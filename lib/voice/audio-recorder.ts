import { audioContext } from "./utils";
import AudioRecordingWorklet from "./worklets/audio-processing";
import VolMeterWorket from "./worklets/vol-meter";

import { createWorketFromSrc } from "./audioworklet-registry";
import EventEmitter from "eventemitter3";

function arrayBufferToBase64(buffer: ArrayBuffer) {
  if (typeof window === 'undefined') {
    throw new Error('arrayBufferToBase64 is not available on server side');
  }
  var binary = "";
  var bytes = new Uint8Array(buffer);
  var len = bytes.byteLength;
  for (var i = 0; i < len; i++) {
    binary += String.fromCharCode(bytes[i]);
  }
  return window.btoa(binary);
}

export class AudioRecorder extends EventEmitter {
  stream: MediaStream | undefined;
  audioContext: AudioContext | undefined;
  source: MediaStreamAudioSourceNode | undefined;
  recording: boolean = false;
  recordingWorklet: AudioWorkletNode | undefined;
  vuWorklet: AudioWorkletNode | undefined;

  private starting: Promise<void> | null = null;

  constructor(public sampleRate = 16000) {
    super();
  }

  async start() {
    if (typeof window === 'undefined') {
      throw new Error('AudioRecorder is not available on server side');
    }
    
    if (!navigator.mediaDevices || !navigator.mediaDevices.getUserMedia) {
      throw new Error("Could not request user media");
    }

    console.log("ðŸŽ™ï¸ AudioRecorder.start() é–‹å§‹");

    this.starting = new Promise(async (resolve, reject) => {
      try {
        console.log("ðŸ“± ãƒžã‚¤ã‚¯ã‚¢ã‚¯ã‚»ã‚¹è¦æ±‚ä¸­...");
        this.stream = await navigator.mediaDevices.getUserMedia({ audio: true });
        console.log("âœ… ãƒžã‚¤ã‚¯ã‚¹ãƒˆãƒªãƒ¼ãƒ å–å¾—æˆåŠŸ:", this.stream);
        
        // ã‚ªãƒ¼ãƒ‡ã‚£ã‚ªãƒˆãƒ©ãƒƒã‚¯ã®è©³ç´°æƒ…å ±ã‚’ãƒ­ã‚°å‡ºåŠ›
        const audioTracks = this.stream.getAudioTracks();
        if (audioTracks.length > 0) {
          const track = audioTracks[0];
          const settings = track.getSettings();
          console.log("ðŸŽ¤ ãƒˆãƒ©ãƒƒã‚¯è©³ç´°:", {
            enabled: track.enabled,
            muted: track.muted,
            readyState: track.readyState,
            settings: settings,
            sampleRate: settings.sampleRate,
            channelCount: settings.channelCount,
          });
        }

        console.log("ðŸ”§ AudioContextä½œæˆä¸­...");
        this.audioContext = await audioContext({ sampleRate: this.sampleRate });
        console.log("âœ… AudioContextä½œæˆæˆåŠŸ:", this.audioContext);
        
        this.source = this.audioContext.createMediaStreamSource(this.stream);
        console.log("ðŸ”— MediaStreamSourceä½œæˆæˆåŠŸ");
      } catch (error) {
        console.error("âŒ ãƒžã‚¤ã‚¯ã‚¢ã‚¯ã‚»ã‚¹ã¾ãŸã¯AudioContextä½œæˆã‚¨ãƒ©ãƒ¼:", error);
        reject(error);
        return;
      }

      console.log("ðŸ”§ AudioWorkletè¨­å®šé–‹å§‹...");
      const workletName = "audio-recorder-worklet";
      const src = createWorketFromSrc(workletName, AudioRecordingWorklet);

      console.log("ðŸ“¦ AudioWorkletãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«è¿½åŠ ä¸­...");
      await this.audioContext.audioWorklet.addModule(src);
      console.log("âœ… AudioWorkletãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«è¿½åŠ æˆåŠŸ");
      
      this.recordingWorklet = new AudioWorkletNode(
        this.audioContext,
        workletName,
      );
      console.log("ðŸŽµ AudioWorkletNodeä½œæˆæˆåŠŸ");

      this.recordingWorklet.port.onmessage = async (ev: MessageEvent) => {
        // worklet processes recording floats and messages converted buffer
        const arrayBuffer = ev.data.data.int16arrayBuffer;

        console.log("ðŸ”Š AudioWorkletã‹ã‚‰ãƒ‡ãƒ¼ã‚¿å—ä¿¡:", {
          hasArrayBuffer: !!arrayBuffer,
          bufferSize: arrayBuffer ? arrayBuffer.byteLength : 0,
          event: ev.data.event
        });

        if (arrayBuffer) {
          const arrayBufferString = arrayBufferToBase64(arrayBuffer);
          console.log("ðŸ“¤ éŸ³å£°ãƒ‡ãƒ¼ã‚¿é€ä¿¡æº–å‚™å®Œäº†, ã‚µã‚¤ã‚º:", arrayBufferString.length);
          this.emit("data", arrayBufferString);
        }
      };
      
      this.source.connect(this.recordingWorklet);
      console.log("ðŸ”— AudioWorkletæŽ¥ç¶šå®Œäº†");

      // vu meter worklet
      console.log("ðŸ“Š VUãƒ¡ãƒ¼ã‚¿ãƒ¼è¨­å®šé–‹å§‹...");
      const vuWorkletName = "vu-meter";
      await this.audioContext.audioWorklet.addModule(
        createWorketFromSrc(vuWorkletName, VolMeterWorket),
      );
      console.log("âœ… VUãƒ¡ãƒ¼ã‚¿ãƒ¼ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«è¿½åŠ æˆåŠŸ");
      
      this.vuWorklet = new AudioWorkletNode(this.audioContext, vuWorkletName);
      console.log("ðŸ“Š VUãƒ¡ãƒ¼ã‚¿ãƒ¼Nodeä½œæˆæˆåŠŸ");
      
      this.vuWorklet.port.onmessage = (ev: MessageEvent) => {
        console.log("ðŸ”‰ éŸ³é‡ãƒ‡ãƒ¼ã‚¿å—ä¿¡:", ev.data.volume);
        this.emit("volume", ev.data.volume);
      };

      this.source.connect(this.vuWorklet);
      console.log("ðŸ”— VUãƒ¡ãƒ¼ã‚¿ãƒ¼æŽ¥ç¶šå®Œäº†");
      
      this.recording = true;
      console.log("ðŸŽ¤ éŒ²éŸ³é–‹å§‹å®Œäº†ï¼");
      resolve();
      this.starting = null;
    });
  }

  stop() {
    // its plausible that stop would be called before start completes
    // such as if the websocket immediately hangs up
    const handleStop = () => {
      this.source?.disconnect();
      this.stream?.getTracks().forEach((track) => track.stop());
      this.stream = undefined;
      this.recordingWorklet = undefined;
      this.vuWorklet = undefined;
    };
    if (this.starting) {
      this.starting.then(handleStop);
      return;
    }
    handleStop();
  }
} 